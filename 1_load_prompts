name: Load Prompts for Diffusion Evaluation
description: Load or create prompts/class labels for diffusion model evaluation. Supports loading from files (txt, json, dataset), inline comma-separated lists, or HuggingFace datasets. One of input_path, prompts_list, or dataset_name must be provided.

inputs:
  - name: input_path
    type: String
    description: 'Path to input prompts file (optional if using prompts_list or dataset_name)'
    default: ''
  - name: prompts_list
    type: String
    description: 'Comma-separated list of prompts/class labels (e.g., "cat,dog,bird")'
    default: ''
  - name: dataset_name
    type: String
    description: 'HuggingFace dataset name (e.g., "Gustavosta/Stable-Diffusion-Prompts")'
    default: ''
  - name: max_prompts
    type: String
    description: 'Maximum number of prompts to load'
    default: '100'
  - name: input_format
    type: String
    description: 'Input format: txt, json, dataset, list'
    default: 'txt'

outputs:
  - name: prompts
    type: Data
    description: 'JSON file containing loaded prompts with count metadata'

metadata:
  annotations:
    author: Load Prompts Component

implementation:
  container:
    image: kushagra4761/nesy-factory-gpu:t2.6v2
    command:
      - sh
      - -c
      - |
        set -e
        echo "Installing benchmarking dependencies..."
        pip install --no-cache-dir \
          pillow>=10.0.0 \
          diffusers>=0.25.0 \
          safetensors>=0.4.0 \
          torchmetrics>=1.2.0 \
          torch-fidelity>=0.3.0 \
          scipy>=1.11.0 \
          --break-system-packages > /dev/null 2>&1
        
        echo "Dependencies installed. Starting component..."
        echo ""
        
        "$0" "$@"
      - python3
      - -u
      - -c
      - |
        def _make_parent_dirs_and_return_path(file_path):
            import os
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            return file_path
        
        def load_prompts_component(
            input_path,
            prompts_list,
            dataset_name,
            max_prompts,
            input_format,
            output_prompts_path,
        ):
            import os
            import sys
            import json
            import logging
            from pathlib import Path
            from typing import List
            
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            logger = logging.getLogger('load_prompts')
            
            def ensure_directory_exists(file_path):
                directory = os.path.dirname(file_path)
                if directory and not os.path.exists(directory):
                    os.makedirs(directory, exist_ok=True)
                    logger.info(f'Created directory: {directory}')
            
            def create_prompts_from_list(prompts_string: str, max_prompts: int) -> List[str]:
                logger.info('Creating prompts from inline list')
                prompts = [p.strip() for p in prompts_string.split(',') if p.strip()]
                logger.info(f'Parsed {len(prompts)} prompts from list')
                return prompts[:max_prompts]
            
            def load_prompts_from_txt(filepath: str, max_prompts: int) -> List[str]:
                logger.info(f'Loading prompts from TXT file: {filepath}')
                with open(filepath, 'r', encoding='utf-8') as f:
                    prompts = [line.strip() for line in f if line.strip()]
                logger.info(f'Loaded {len(prompts)} prompts from TXT file')
                return prompts[:max_prompts]
            
            def load_prompts_from_json(filepath: str, max_prompts: int, key: str = 'prompts') -> List[str]:
                logger.info(f'Loading prompts from JSON file: {filepath}')
                with open(filepath, 'r') as f:
                    data = json.load(f)
                
                if key in data:
                    prompts = data[key]
                elif 'text' in data:
                    prompts = data['text']
                elif isinstance(data, list):
                    prompts = data
                else:
                    available_keys = list(data.keys()) if isinstance(data, dict) else []
                    raise ValueError(
                        f'Could not find prompts in JSON. '
                        f'Available keys: {available_keys}'
                    )
                
                logger.info(f'Loaded {len(prompts)} prompts from JSON file')
                return prompts[:max_prompts]
            
            def load_prompts_from_dataset(filepath: str, max_prompts: int, text_column: str = 'text') -> List[str]:
                logger.info(f'Loading prompts from HuggingFace dataset: {filepath}')
                
                try:
                    from datasets import load_from_disk, load_dataset
                except ImportError:
                    logger.error('datasets library not found. Install with: pip install datasets')
                    raise
                
                try:
                    logger.info('Attempting to load from disk...')
                    dataset = load_from_disk(filepath)
                except Exception as e:
                    logger.info(f'Could not load from disk ({e}), trying HuggingFace Hub...')
                    dataset = load_dataset(filepath, split='train')
                
                prompts = [item[text_column] for item in dataset]
                logger.info(f'Loaded {len(prompts)} prompts from dataset')
                return prompts[:max_prompts]
            
            # Convert max_prompts to int
            max_prompts_int = int(max_prompts)
            
            logger.info('='*80)
            logger.info('LOAD PROMPTS COMPONENT')
            logger.info('='*80)
            logger.info(f'Output path: {output_prompts_path}')
            logger.info(f'Max prompts: {max_prompts_int}')
            logger.info('')
            
            try:
                ensure_directory_exists(output_prompts_path)
                
                prompts = None
                
                # Mode 1: Create from inline list
                if prompts_list and prompts_list.strip():
                    logger.info('Mode: Create from inline list')
                    preview = prompts_list[:100]
                    logger.info(f'Prompts list preview: {preview}...')
                    logger.info('')
                    
                    prompts = create_prompts_from_list(prompts_list, max_prompts_int)
                    logger.info(f'✓ Created {len(prompts)} prompts from list')
                
                # Mode 2: Load from HuggingFace dataset
                elif dataset_name and dataset_name.strip():
                    logger.info('Mode: Load from HuggingFace dataset')
                    logger.info(f'Dataset: {dataset_name}')
                    logger.info('')
                    
                    prompts = load_prompts_from_dataset(dataset_name, max_prompts_int)
                    logger.info(f'✓ Loaded {len(prompts)} prompts from dataset')
                
                # Mode 3: Load from file
                elif input_path and input_path.strip():
                    logger.info('Mode: Load from file')
                    logger.info(f'Input path: {input_path}')
                    logger.info(f'Format: {input_format}')
                    logger.info('')
                    
                    if not os.path.exists(input_path):
                        raise FileNotFoundError(f'Input file not found: {input_path}')
                    
                    if input_format == 'txt':
                        prompts = load_prompts_from_txt(input_path, max_prompts_int)
                    elif input_format == 'json':
                        prompts = load_prompts_from_json(input_path, max_prompts_int)
                    elif input_format == 'dataset':
                        prompts = load_prompts_from_dataset(input_path, max_prompts_int)
                    else:
                        raise ValueError(f'Unknown format: {input_format}')
                    
                    logger.info(f'✓ Loaded {len(prompts)} prompts from file')
                
                else:
                    raise ValueError(
                        'Must provide one of: input_path, prompts_list, or dataset_name'
                    )
                
                # Validate prompts
                if not prompts or len(prompts) == 0:
                    raise ValueError('No prompts loaded!')
                
                # Apply max_prompts limit
                if len(prompts) > max_prompts_int:
                    logger.info(f'Limiting to {max_prompts_int} prompts (from {len(prompts)})')
                    prompts = prompts[:max_prompts_int]
                
                # Show sample
                logger.info('')
                logger.info('Sample prompts:')
                for i, prompt in enumerate(prompts[:5], 1):
                    preview = str(prompt)[:80] + ('...' if len(str(prompt)) > 80 else '')
                    logger.info(f'  {i}. {preview}')
                
                # Prepare output data
                output_data = {
                    'prompts': prompts,
                    'count': len(prompts),
                    'max_prompts': max_prompts_int
                }
                
                # Save output
                logger.info('')
                logger.info(f'Saving to {output_prompts_path}...')
                with open(output_prompts_path, 'w', encoding='utf-8') as f:
                    json.dump(output_data, f, indent=2, ensure_ascii=False)
                
                logger.info(f'✓ Saved {len(prompts)} prompts')
                
                logger.info('')
                logger.info('='*80)
                logger.info('PROMPTS LOADING COMPLETED')
                logger.info('='*80)
                logger.info(f'Total prompts: {len(prompts)}')
                logger.info(f'Output file: {output_prompts_path}')
                logger.info('='*80)
                
            except FileNotFoundError as e:
                logger.error(f'FILE NOT FOUND ERROR: {str(e)}')
                import traceback
                traceback.print_exc()
                sys.exit(1)
            except ValueError as e:
                logger.error(f'VALIDATION ERROR: {str(e)}')
                import traceback
                traceback.print_exc()
                sys.exit(1)
            except Exception as e:
                logger.error(f'ERROR: {str(e)}')
                import traceback
                traceback.print_exc()
                sys.exit(1)
        
        import argparse
        _parser = argparse.ArgumentParser(prog='Load Prompts for Diffusion Evaluation', description='Load or create prompts for diffusion model evaluation')
        _parser.add_argument('--input_path', dest='input_path', type=str, required=False, default='')
        _parser.add_argument('--prompts_list', dest='prompts_list', type=str, required=False, default='')
        _parser.add_argument('--dataset_name', dest='dataset_name', type=str, required=False, default='')
        _parser.add_argument('--max_prompts', dest='max_prompts', type=str, required=False, default='100')
        _parser.add_argument('--input_format', dest='input_format', type=str, required=False, default='txt')
        _parser.add_argument('--output_prompts', dest='output_prompts_path', type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())
        load_prompts_component(**_parsed_args)

    args:
      - --input_path
      - {inputValue: input_path}
      - --prompts_list
      - {inputValue: prompts_list}
      - --dataset_name
      - {inputValue: dataset_name}
      - --max_prompts
      - {inputValue: max_prompts}
      - --input_format
      - {inputValue: input_format}
      - --output_prompts
      - {outputPath: prompts}
